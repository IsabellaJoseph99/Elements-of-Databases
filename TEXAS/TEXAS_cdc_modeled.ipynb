{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery error in mk operation: Dataset 'sunny-advantage-266802:cdc_modeled'\n",
      "already exists.\n"
     ]
    }
   ],
   "source": [
    "dataset_id = \"TEXAS_cdc_modeled\"\n",
    "!bq --location=US mk --dataset cdc_modeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2011 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_Each_survey_member_2011\n",
    "  AS (SELECT SEQNO\n",
    "      FROM TEXAS_cdc_staging.2011\n",
    "     where _STATE = 48);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  14973"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(SEQNO) from TEXAS_cdc_modeled.TEXAS_Each_survey_member_2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  14973"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct SEQNO) from TEXAS_cdc_modeled.TEXAS_Each_survey_member_2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This confirms that the SEQNO is the PK ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_DEMOGRAPHIC_2011 AS\n",
    "SELECT * FROM(\n",
    "SELECT distinct SEQNO, _STATE, SEX, MARITAL, EDUCA, EMPLOY, CHILDREN, INCOME2, WEIGHT2, HEIGHT3 from TEXAS_cdc_staging.2011\n",
    "WHERE _STATE = 48\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_OVERALL_Health_Status_2011 AS\n",
    "SELECT * FROM(\n",
    "SELECT SEQNO, _STATE, GENHLTH, PHYSHLTH, MENTHLTH from TEXAS_cdc_staging.2011 \n",
    "WHERE _STATE=48\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQNO</th>\n",
       "      <th>_STATE</th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>PHYSHLTH</th>\n",
       "      <th>MENTHLTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.011011e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.011010e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.011010e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.011002e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.011004e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.011003e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.011006e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.011010e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.011008e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.011003e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.011013e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.011012e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SEQNO  _STATE  GENHLTH  PHYSHLTH  MENTHLTH\n",
       "0   2.011011e+09    48.0      2.0       2.0      88.0\n",
       "1   2.011010e+09    48.0      2.0       2.0       5.0\n",
       "2   2.011010e+09    48.0      2.0       2.0       2.0\n",
       "3   2.011002e+09    48.0      2.0       2.0      88.0\n",
       "4   2.011004e+09    48.0      2.0       2.0      88.0\n",
       "5   2.011003e+09    48.0      2.0       2.0      88.0\n",
       "6   2.011006e+09    48.0      2.0       2.0      88.0\n",
       "7   2.011010e+09    48.0      2.0       2.0      88.0\n",
       "8   2.011008e+09    48.0      2.0       2.0      88.0\n",
       "9   2.011003e+09    48.0      2.0       2.0      88.0\n",
       "10  2.011013e+09    48.0      2.0       2.0      88.0\n",
       "11  2.011012e+09    48.0      2.0       2.0       2.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT * from TEXAS_cdc_modeled.TEXAS_OVERALL_Health_Status_2011 limit 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  14973"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(SEQNO) from TEXAS_cdc_modeled.TEXAS_OVERALL_Health_Status_2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_HEALTH_CARE_2011 AS\n",
    "SELECT * FROM(\n",
    "SELECT SEQNO, _STATE, HLTHPLN1, PERSDOC2, MEDCOST, CHECKUP1 from TEXAS_cdc_staging.2011\n",
    "WHERE _STATE=48\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  14973"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(SEQNO) from TEXAS_cdc_modeled.TEXAS_HEALTH_CARE_2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_TOBACCO_USE_2011 AS\n",
    "SELECT * FROM(\n",
    "SELECT SEQNO, _STATE, SMOKE100, SMOKDAY2, LASTSMK2, USENOW3 from TEXAS_cdc_staging.2011\n",
    "WHERE _STATE=48\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  14973"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(SEQNO) from TEXAS_cdc_modeled.TEXAS_TOBACCO_USE_2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2012 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_Each_survey_member_2012\n",
    "  AS (SELECT SEQNO\n",
    "      FROM TEXAS_cdc_staging.2012\n",
    "     where _STATE = 48);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f0_\n",
       "0  9129"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(SEQNO) from TEXAS_cdc_modeled.TEXAS_Each_survey_member_2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f0_\n",
       "0  9129"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct SEQNO) from TEXAS_cdc_modeled.TEXAS_Each_survey_member_2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_DEMOGRAPHIC_2012 AS\n",
    "SELECT * FROM(\n",
    "SELECT distinct SEQNO, _STATE, SEX, MARITAL, EDUCA, EMPLOY, CHILDREN, INCOME2, WEIGHT2, HEIGHT3 from TEXAS_cdc_staging.2012\n",
    "WHERE _STATE = 48\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_OVERALL_Health_Status_2012 AS\n",
    "SELECT * FROM(\n",
    "SELECT SEQNO, _STATE, GENHLTH, PHYSHLTH, MENTHLTH from TEXAS_cdc_staging.2012\n",
    "WHERE _STATE=48\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQNO</th>\n",
       "      <th>_STATE</th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>PHYSHLTH</th>\n",
       "      <th>MENTHLTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.012005e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.012004e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.012002e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.012003e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.012004e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.012001e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.012000e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.012008e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.012007e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.012004e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.012007e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.012007e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SEQNO  _STATE  GENHLTH  PHYSHLTH  MENTHLTH\n",
       "0   2.012005e+09    48.0      7.0       2.0       1.0\n",
       "1   2.012004e+09    48.0      2.0       2.0      88.0\n",
       "2   2.012002e+09    48.0      2.0       2.0       2.0\n",
       "3   2.012003e+09    48.0      2.0       2.0       1.0\n",
       "4   2.012004e+09    48.0      2.0       2.0      88.0\n",
       "5   2.012001e+09    48.0      2.0       2.0       4.0\n",
       "6   2.012000e+09    48.0      2.0       2.0      88.0\n",
       "7   2.012008e+09    48.0      2.0       2.0      88.0\n",
       "8   2.012007e+09    48.0      2.0       2.0      88.0\n",
       "9   2.012004e+09    48.0      2.0       2.0      10.0\n",
       "10  2.012007e+09    48.0      2.0       2.0      88.0\n",
       "11  2.012007e+09    48.0      2.0       2.0       3.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT * from TEXAS_cdc_modeled.TEXAS_OVERALL_Health_Status_2012 limit 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f0_\n",
       "0  9129"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(SEQNO) from TEXAS_cdc_modeled.TEXAS_OVERALL_Health_Status_2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_HEALTH_CARE_2012 AS\n",
    "SELECT * FROM(\n",
    "SELECT SEQNO, _STATE, HLTHPLN1, PERSDOC2, MEDCOST, CHECKUP1 from TEXAS_cdc_staging.2012\n",
    "WHERE _STATE=48\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f0_\n",
       "0  9129"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(SEQNO) from TEXAS_cdc_modeled.TEXAS_HEALTH_CARE_2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_TOBACCO_USE_2012 AS\n",
    "SELECT * FROM(\n",
    "SELECT SEQNO, _STATE, SMOKE100, SMOKDAY2, LASTSMK2, USENOW3 from TEXAS_cdc_staging.2012\n",
    "WHERE _STATE=48\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2013 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_Each_survey_member_2013\n",
    "  AS (SELECT SEQNO\n",
    "      FROM TEXAS_cdc_staging.2013\n",
    "     where _STATE = 48);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  10917"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(SEQNO) from TEXAS_cdc_modeled.TEXAS_Each_survey_member_2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  10917"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct SEQNO) from TEXAS_cdc_modeled.TEXAS_Each_survey_member_2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_DEMOGRAPHIC_2013 AS\n",
    "SELECT * FROM(\n",
    "SELECT distinct SEQNO, _STATE, SEX, MARITAL, EDUCA, EMPLOY1, CHILDREN, INCOME2, WEIGHT2, HEIGHT3 from TEXAS_cdc_staging.2013\n",
    "WHERE _STATE = 48\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_OVERALL_Health_Status_2013 AS\n",
    "SELECT * FROM(\n",
    "SELECT SEQNO, _STATE, GENHLTH, PHYSHLTH, MENTHLTH from TEXAS_cdc_staging.2013\n",
    "WHERE _STATE=48\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_HEALTH_CARE_2013 AS\n",
    "SELECT * FROM(\n",
    "SELECT SEQNO, _STATE, HLTHPLN1, PERSDOC2, MEDCOST, CHECKUP1 from TEXAS_cdc_staging.2013\n",
    "WHERE _STATE=48\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_TOBACCO_USE_2013 AS\n",
    "SELECT * FROM(\n",
    "SELECT SEQNO, _STATE, SMOKE100, SMOKDAY2, LASTSMK2, USENOW3 from TEXAS_cdc_staging.2013\n",
    "WHERE _STATE=48\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tables have been created for 2011, 2012 and 2013 for Each_survey_member, OVERALL_Health_Status, HEALTH_CARE, TOBACCO_USE and ALCOHOL_CONSUMPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Unionizing the yearly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_Each_survey_member_float AS\n",
    "SELECT * FROM(\n",
    "SELECT SEQNO\n",
    "FROM TEXAS_cdc_modeled.TEXAS_Each_survey_member_2011\n",
    "UNION ALL\n",
    "SELECT SEQNO\n",
    "FROM TEXAS_cdc_modeled.TEXAS_Each_survey_member_2012\n",
    "UNION ALL\n",
    "SELECT SEQNO\n",
    "FROM TEXAS_cdc_modeled.TEXAS_Each_survey_member_2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_DEMOGRAPHIC_float AS\n",
    "SELECT * FROM(\n",
    "SELECT SEQNO, _STATE, SEX, MARITAL, EDUCA, EMPLOY, CHILDREN, INCOME2, WEIGHT2, HEIGHT3\n",
    "FROM TEXAS_cdc_modeled.TEXAS_DEMOGRAPHIC_2011\n",
    "UNION ALL\n",
    "SELECT SEQNO, _STATE, SEX, MARITAL, EDUCA, EMPLOY, CHILDREN, INCOME2, WEIGHT2, HEIGHT3\n",
    "FROM TEXAS_cdc_modeled.TEXAS_DEMOGRAPHIC_2012\n",
    "UNION ALL\n",
    "SELECT SEQNO, _STATE, SEX, MARITAL, EDUCA, EMPLOY1, CHILDREN, INCOME2, WEIGHT2, HEIGHT3\n",
    "FROM TEXAS_cdc_modeled.TEXAS_DEMOGRAPHIC_2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_OVERALL_Health_Status_float AS\n",
    "SELECT * FROM(\n",
    "SELECT SEQNO, _STATE, GENHLTH, PHYSHLTH, MENTHLTH\n",
    "FROM TEXAS_cdc_modeled.TEXAS_OVERALL_Health_Status_2011\n",
    "UNION ALL\n",
    "SELECT SEQNO, _STATE, GENHLTH, PHYSHLTH, MENTHLTH\n",
    "FROM TEXAS_cdc_modeled.TEXAS_OVERALL_Health_Status_2012\n",
    "UNION ALL\n",
    "SELECT SEQNO, _STATE, GENHLTH, PHYSHLTH, MENTHLTH\n",
    "FROM TEXAS_cdc_modeled.TEXAS_OVERALL_Health_Status_2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_HEALTH_CARE_float AS\n",
    "SELECT * FROM(\n",
    "SELECT SEQNO, _STATE, HLTHPLN1, PERSDOC2, MEDCOST, CHECKUP1\n",
    "FROM TEXAS_cdc_modeled.TEXAS_HEALTH_CARE_2011\n",
    "UNION ALL\n",
    "SELECT SEQNO, _STATE, HLTHPLN1, PERSDOC2, MEDCOST, CHECKUP1\n",
    "FROM TEXAS_cdc_modeled.TEXAS_HEALTH_CARE_2012\n",
    "UNION ALL\n",
    "SELECT SEQNO, _STATE, HLTHPLN1, PERSDOC2, MEDCOST, CHECKUP1\n",
    "FROM TEXAS_cdc_modeled.TEXAS_HEALTH_CARE_2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_TOBACCO_USE_float AS\n",
    "SELECT * FROM(\n",
    "SELECT SEQNO, _STATE, SMOKE100, SMOKDAY2, LASTSMK2, USENOW3\n",
    "FROM TEXAS_cdc_modeled.TEXAS_TOBACCO_USE_2011\n",
    "UNION ALL\n",
    "SELECT SEQNO, _STATE, SMOKE100, SMOKDAY2, LASTSMK2, USENOW3\n",
    "FROM TEXAS_cdc_modeled.TEXAS_TOBACCO_USE_2012\n",
    "UNION ALL\n",
    "SELECT SEQNO, _STATE, SMOKE100, SMOKDAY2, LASTSMK2, USENOW3\n",
    "FROM TEXAS_cdc_modeled.TEXAS_TOBACCO_USE_2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CASTING ALL THE FLOAT VALUES TO INT ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_Each_survey_member AS\n",
    "SELECT CAST(SEQNO AS INT64) SEQNO FROM TEXAS_cdc_modeled.TEXAS_Each_survey_member_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_DEMOGRAPHIC AS\n",
    "SELECT CAST(SEQNO AS INT64) SEQNO, \n",
    "CAST(_STATE AS INT64) _STATE, \n",
    "CAST(SEX AS INT64) SEX, \n",
    "CAST (MARITAL AS INT64) MARITAL, \n",
    "CAST (EDUCA  AS INT64) EDUCA, \n",
    "CAST (EMPLOY  AS INT64) EMPLOY, \n",
    "CAST (CHILDREN  AS INT64) CHILDREN, \n",
    "CAST (INCOME2  AS INT64) INCOME2, \n",
    "CAST (WEIGHT2  AS INT64) WEIGHT2, \n",
    "CAST (HEIGHT3  AS INT64) HEIGHT3\n",
    "FROM TEXAS_cdc_modeled.TEXAS_DEMOGRAPHIC_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_OVERALL_Health_Status AS\n",
    "SELECT CAST(SEQNO AS INT64) SEQNO, \n",
    "CAST(_STATE AS INT64) _STATE, \n",
    "CAST(GENHLTH AS INT64) GENHLTH, \n",
    "CAST (PHYSHLTH AS INT64) PHYSHLTH, \n",
    "CAST (MENTHLTH  AS INT64) MENTHLTH, \n",
    "FROM TEXAS_cdc_modeled.TEXAS_OVERALL_Health_Status_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_HEALTH_CARE AS\n",
    "SELECT CAST(SEQNO AS INT64) SEQNO, \n",
    "CAST(_STATE AS INT64) _STATE, \n",
    "CAST(HLTHPLN1 AS INT64) HLTHPLN1, \n",
    "CAST (PERSDOC2 AS INT64) PERSDOC2, \n",
    "CAST (MEDCOST  AS INT64) MEDCOST, \n",
    "CAST (CHECKUP1  AS INT64) CHECKUP1, \n",
    "FROM TEXAS_cdc_modeled.TEXAS_HEALTH_CARE_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE TEXAS_cdc_modeled.TEXAS_TOBACCO_USE AS\n",
    "SELECT CAST(SEQNO AS INT64) SEQNO, \n",
    "CAST(_STATE AS INT64) _STATE, \n",
    "CAST( SMOKE100 AS INT64)  SMOKE100, \n",
    "CAST (SMOKDAY2 AS INT64) SMOKDAY2, \n",
    "CAST (LASTSMK2  AS INT64) LASTSMK2, \n",
    "CAST (USENOW3  AS INT64) USENOW3, \n",
    "FROM TEXAS_cdc_modeled.TEXAS_TOBACCO_USE_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### There are no foreign key violations, because the only foreign key we are using is also our primary key (SEQ NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Interactive Beam requires Python 3.5.3+.\n",
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_results PCollection[Read from BigQuery.None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.internal.gcp.auth:Setting socket default timeout to 60 seconds.\n",
      "INFO:apache_beam.internal.gcp.auth:socket default timeout is 60.0 seconds.\n",
      "INFO:oauth2client.transport:Attempting refresh to obtain initial access_token\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'cdc_modeled'\n",
      " projectId: 'sunny-advantage-266802'\n",
      " tableId: 'DEMOGRAPHIC'> referenced by query SELECT SEQNO, _STATE, SEX, MARITAL, EDUCA, EMPLOY, CHILDREN, INCOME2, WEIGHT2, HEIGHT3  FROM cdc_modeled.DEMOGRAPHIC limit 50\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset sunny-advantage-266802:temp_dataset_e1ac707cc12d4c738de396fe5089503c does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table sunny-advantage-266802.cdc_modeled.DEMOGRAPHIC_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'SEQNO'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: '_STATE'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'SEX'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'MARITAL'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'EDUCA'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'EMPLOY'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'CHILDREN'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'INCOME2'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'WEIGHT2'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'HEIGHT3'\n",
      " type: 'INTEGER'>]>. Result: <Table\n",
      " creationTime: 1583691711782\n",
      " etag: '6qAkyfPxqfJwQ74y1KXGlA=='\n",
      " id: 'sunny-advantage-266802:cdc_modeled.DEMOGRAPHIC_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583691711826\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'SEQNO'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: '_STATE'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'SEX'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'MARITAL'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'EDUCA'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'EMPLOY'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'CHILDREN'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'INCOME2'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'WEIGHT2'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'HEIGHT3'\n",
      " type: 'INTEGER'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/sunny-advantage-266802/datasets/cdc_modeled/tables/DEMOGRAPHIC_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'cdc_modeled'\n",
      " projectId: 'sunny-advantage-266802'\n",
      " tableId: 'DEMOGRAPHIC_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n"
     ]
    }
   ],
   "source": [
    "%run DEMOGRAPHIC_beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The above \"%run DEMOGRAPHIC_beam.py\" ran successfully!\n",
    "### a new table was created in our cdc_modeled dataset, and it is called DEMOGRAPHIC_Beam\n",
    "### The DEMOGRAPHIC_beam has all the columns we need.\n",
    "### There are None values present in the input file, but not the output file, showing that out beam pipeline worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Checking to see if SEQNO is primary key for DEMOGRAPHIC_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0   50"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(SEQNO) from cdc_modeled.DEMOGRAPHIC_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0   50"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct SEQNO) from cdc_modeled.DEMOGRAPHIC_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### As count SEQNO and count distinc SEQNO results in the same number, SEQNO is unique and it is out primary key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Demographics is now our main table. It has a PK. As it is not a child table, it does not have a FK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_results PCollection[Read from BigQuery.None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'cdc_modeled'\n",
      " projectId: 'sunny-advantage-266802'\n",
      " tableId: 'DEMOGRAPHIC'> referenced by query SELECT SEQNO, _STATE, SEX, MARITAL, EDUCA, EMPLOY, CHILDREN, INCOME2, WEIGHT2, HEIGHT3  FROM cdc_modeled.DEMOGRAPHIC limit 50\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset sunny-advantage-266802:temp_dataset_7e84692502834f14b5c349440cc9961e does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table sunny-advantage-266802.cdc_modeled.DEMOGRAPHIC_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'SEQNO'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: '_STATE'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'SEX'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'MARITAL'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'EDUCA'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'EMPLOY'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'CHILDREN'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'INCOME2'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'WEIGHT2'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'HEIGHT3'\n",
      " type: 'INTEGER'>]>. Result: <Table\n",
      " creationTime: 1583689450887\n",
      " etag: 'OnPocT0btv/3B+zJcEZcGw=='\n",
      " id: 'sunny-advantage-266802:cdc_modeled.DEMOGRAPHIC_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583689450916\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'SEQNO'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: '_STATE'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'SEX'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'MARITAL'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'EDUCA'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'EMPLOY'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'CHILDREN'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'INCOME2'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'WEIGHT2'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'HEIGHT3'\n",
      " type: 'INTEGER'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/sunny-advantage-266802/datasets/cdc_modeled/tables/DEMOGRAPHIC_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'cdc_modeled'\n",
      " projectId: 'sunny-advantage-266802'\n",
      " tableId: 'DEMOGRAPHIC_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n"
     ]
    }
   ],
   "source": [
    "%run DEMOGRAPHIC_beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://beam_cs327e_data_thedataminers/staging/transform-demographic2.1583518378.783047/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://beam_cs327e_data_thedataminers/staging/transform-demographic2.1583518378.783047/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpr79p6kdm', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://beam_cs327e_data_thedataminers/staging/transform-demographic2.1583518378.783047/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://beam_cs327e_data_thedataminers/staging/transform-demographic2.1583518378.783047/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://beam_cs327e_data_thedataminers/staging/transform-demographic2.1583518378.783047/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpr79p6kdm', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://beam_cs327e_data_thedataminers/staging/transform-demographic2.1583518378.783047/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://beam_cs327e_data_thedataminers/staging/transform-demographic2.1583518378.783047/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://beam_cs327e_data_thedataminers/staging/transform-demographic2.1583518378.783047/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 0 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-03-06T18:13:04.138501Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-03-06_10_13_03-6814820465299323'\n",
      " location: 'us-central1'\n",
      " name: 'transform-demographic2'\n",
      " projectId: 'sunny-advantage-266802'\n",
      " stageStates: []\n",
      " startTime: '2020-03-06T18:13:04.138501Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-03-06_10_13_03-6814820465299323]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-03-06_10_13_03-6814820465299323?project=sunny-advantage-266802\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-06_10_13_03-6814820465299323 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:03.133Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-03-06_10_13_03-6814820465299323. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:03.133Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-03-06_10_13_03-6814820465299323.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:08.060Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:08.801Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-4 in us-central1-c.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:09.647Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:09.738Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 2/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:09.825Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 1/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:09.958Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:10.003Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:10.220Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:10.512Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:10.545Z: JOB_MESSAGE_DETAILED: Fusing consumer Format NULL values into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:10.571Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:10.603Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WriteBundles/WriteBundles into Format NULL values\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:10.633Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Format NULL values\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:10.663Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Pair into Write log 1/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:10.729Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 1/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:10.768Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Reify into Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:10.794Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Write into Write log 1/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:10.824Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 1/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:10.855Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Extract into Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:10.884Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Pair into Write log 2/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:10.907Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 2/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:10.932Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Reify into Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:10.956Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Write into Write log 2/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:10.987Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 2/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:11.022Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Extract into Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:11.125Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/InitializeWrite into Write log 1/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:11.208Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/InitializeWrite into Write log 2/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:11.310Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:11.366Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:11.422Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:11.459Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:11.823Z: JOB_MESSAGE_DEBUG: Executing wait step start29\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:12.095Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:12.136Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:12.165Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:12.195Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:12.218Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-c...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:12.244Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:12.328Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:12.329Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:12.403Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:12.430Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-06_10_13_03-6814820465299323 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:13:45.998Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running step(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:14:58.859Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:14:58.892Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:27.697Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:27.765Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:27.803Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:27.885Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:27.940Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:27.973Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:27.989Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:28.023Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:28.076Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:28.109Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:28.158Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:28.204Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:28.647Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:28.726Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:28.760Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:28.832Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:28.861Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:28.887Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:28.903Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:28.924Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:28.945Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:28.971Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:28.998Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:29.025Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:29.059Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Format NULL values+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:15:30.143Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_3220603751336333034\". You can check its status with the bq tool: \"bq show -j --project_id=sunny-advantage-266802 dataflow_job_3220603751336333034\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:06.265Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_3220603751336333034\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:07.297Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_709857862606007120\" started. You can check its status with the bq tool: \"bq show -j --project_id=sunny-advantage-266802 dataflow_job_709857862606007120\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:37.660Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_709857862606007120\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:37.688Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_709857862606007120\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:42.943Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_3220603751336330494\". You can check its status with the bq tool: \"bq show -j --project_id=sunny-advantage-266802 dataflow_job_3220603751336330494\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:53.442Z: JOB_MESSAGE_BASIC: BigQuery import job \"dataflow_job_3220603751336330494\" done.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:53.929Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Format NULL values+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:54.070Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:54.097Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:54.121Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:54.147Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:54.180Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:54.207Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:56.163Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:56.217Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:56.296Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:56.324Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:56.347Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:56.368Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:56.397Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:56.428Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:56.485Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:59.774Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:59.839Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:59.901Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:59.923Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:59.943Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:17:59.970Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:18:00.003Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:18:00.037Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:18:00.107Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:18:00.433Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:18:00.498Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:18:00.562Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:18:00.606Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:18:00.657Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:18:00.713Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:18:02.625Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:18:02.687Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:18:02.747Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:18:02.796Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:18:02.866Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:18:02.928Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:18:03.515Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:18:06.517Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:18:06.580Z: JOB_MESSAGE_DEBUG: Executing success step success27\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:18:06.698Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:18:06.764Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:18:06.801Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:19:51.271Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 1 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:19:51.316Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-06T18:19:51.345Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-06_10_13_03-6814820465299323 is in state JOB_STATE_DONE\n"
     ]
    }
   ],
   "source": [
    "%run DEMOGRAPHIC_beam_dataflow.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_results PCollection[Read from BigQuery.None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'cdc_modeled'\n",
      " projectId: 'sunny-advantage-266802'\n",
      " tableId: 'HEALTH_CARE'> referenced by query SELECT SEQNO, _STATE, HLTHPLN1, PERSDOC2, MEDCOST, CHECKUP1 FROM cdc_modeled.HEALTH_CARE limit 50\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset sunny-advantage-266802:temp_dataset_382a21c238c7447fb494fa2df82b8049 does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table sunny-advantage-266802.cdc_modeled.HEALTH_CARE_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'SEQNO'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: '_STATE'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'HLTHPLN1'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'PERSDOC2'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'MEDCOST'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'CHECKUP1'\n",
      " type: 'INTEGER'>]>. Result: <Table\n",
      " creationTime: 1583677739324\n",
      " etag: 'gBj4k+hYglqFHLKnC3yZTg=='\n",
      " id: 'sunny-advantage-266802:cdc_modeled.HEALTH_CARE_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583677739361\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'SEQNO'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: '_STATE'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'HLTHPLN1'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'PERSDOC2'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'MEDCOST'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'CHECKUP1'\n",
      " type: 'INTEGER'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/sunny-advantage-266802/datasets/cdc_modeled/tables/HEALTH_CARE_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'cdc_modeled'\n",
      " projectId: 'sunny-advantage-266802'\n",
      " tableId: 'HEALTH_CARE_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n"
     ]
    }
   ],
   "source": [
    "%run HEALTH_CARE_beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://beam_cs327e_data_thedataminers/staging/transform-health-care-2.1583678138.414827/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://beam_cs327e_data_thedataminers/staging/transform-health-care-2.1583678138.414827/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpbiqazgit', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://beam_cs327e_data_thedataminers/staging/transform-health-care-2.1583678138.414827/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://beam_cs327e_data_thedataminers/staging/transform-health-care-2.1583678138.414827/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://beam_cs327e_data_thedataminers/staging/transform-health-care-2.1583678138.414827/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpbiqazgit', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://beam_cs327e_data_thedataminers/staging/transform-health-care-2.1583678138.414827/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://beam_cs327e_data_thedataminers/staging/transform-health-care-2.1583678138.414827/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://beam_cs327e_data_thedataminers/staging/transform-health-care-2.1583678138.414827/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 1 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-03-08T14:35:43.921179Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-03-08_07_35_42-2169767173921659007'\n",
      " location: 'us-central1'\n",
      " name: 'transform-health-care-2'\n",
      " projectId: 'sunny-advantage-266802'\n",
      " stageStates: []\n",
      " startTime: '2020-03-08T14:35:43.921179Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-03-08_07_35_42-2169767173921659007]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-03-08_07_35_42-2169767173921659007?project=sunny-advantage-266802\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_07_35_42-2169767173921659007 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:42.758Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-03-08_07_35_42-2169767173921659007. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:42.758Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-03-08_07_35_42-2169767173921659007.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:47.213Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:47.945Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-4 in us-central1-c.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:48.513Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:48.546Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 2/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:48.566Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 1/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:48.594Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:48.618Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:48.701Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:48.960Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:48.990Z: JOB_MESSAGE_DETAILED: Fusing consumer Format NULL values into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.018Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.046Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WriteBundles/WriteBundles into Format NULL values\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.073Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Format NULL values\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.102Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Pair into Write log 1/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.131Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 1/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.161Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Reify into Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.186Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Write into Write log 1/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.210Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 1/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.237Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Extract into Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.258Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Pair into Write log 2/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.282Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 2/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.308Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Reify into Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.329Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Write into Write log 2/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.350Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 2/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.377Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Extract into Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.404Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/InitializeWrite into Write log 1/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.428Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/InitializeWrite into Write log 2/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.455Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.485Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.510Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.538Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.900Z: JOB_MESSAGE_DEBUG: Executing wait step start29\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.962Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.983Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:49.994Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:50.005Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:50.017Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-c...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:50.024Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:50.079Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:50.079Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:50.136Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:35:50.157Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_07_35_42-2169767173921659007 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:36:17.995Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running step(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:37:34.063Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:37:34.096Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:04.391Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:04.517Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:04.518Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:04.556Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:04.601Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:04.632Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:04.731Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:04.783Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:04.795Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:04.824Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:04.875Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:04.920Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:04.960Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:04.974Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:05.014Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:05.030Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:05.030Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:05.037Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:05.063Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:05.067Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:05.090Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:05.123Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:05.151Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:05.181Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:05.209Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Format NULL values+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:38:06.299Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_8787077992012454051\". You can check its status with the bq tool: \"bq show -j --project_id=sunny-advantage-266802 dataflow_job_8787077992012454051\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:39:13.007Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_8787077992012454051\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:39:13.807Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_6046746483179746516\" started. You can check its status with the bq tool: \"bq show -j --project_id=sunny-advantage-266802 dataflow_job_6046746483179746516\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:39:44.137Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_6046746483179746516\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:39:44.164Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_6046746483179746516\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:39:49.597Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_8787077992012454383\". You can check its status with the bq tool: \"bq show -j --project_id=sunny-advantage-266802 dataflow_job_8787077992012454383\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:00.025Z: JOB_MESSAGE_BASIC: BigQuery import job \"dataflow_job_8787077992012454383\" done.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:00.779Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Format NULL values+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:00.843Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:00.868Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:00.886Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:00.908Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:00.933Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:00.974Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:04.056Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:04.120Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:04.248Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:04.271Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:04.294Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:04.316Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:04.348Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:04.373Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:04.428Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:06.372Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:06.430Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:06.479Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:06.503Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:06.550Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:06.573Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:06.606Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:06.632Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:06.669Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:08.368Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:08.423Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:08.479Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:08.527Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:08.580Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:08.637Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:09.462Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:09.511Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:09.564Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:09.608Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:09.666Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:09.724Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:12.344Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:13.257Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:13.328Z: JOB_MESSAGE_DEBUG: Executing success step success27\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:13.538Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:13.598Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:40:13.635Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:41:47.513Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 1 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:41:47.551Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T14:41:47.579Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_07_35_42-2169767173921659007 is in state JOB_STATE_DONE\n"
     ]
    }
   ],
   "source": [
    "%run HEALTH_CARE_beam_dataflow.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_results PCollection[Read from BigQuery.None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'cdc_modeled'\n",
      " projectId: 'sunny-advantage-266802'\n",
      " tableId: 'OVERALL_Health_Status'> referenced by query SELECT SEQNO, _STATE, GENHLTH, PHYSHLTH, MENTHLTH FROM cdc_modeled.OVERALL_Health_Status limit 50\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset sunny-advantage-266802:temp_dataset_ad70199a1769427b8664a64e5c6b446a does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table sunny-advantage-266802.cdc_modeled.OVERALL_Health_Status_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'SEQNO'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: '_STATE'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'GENHLTH'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'PHYSHLTH'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'MENTHLTH'\n",
      " type: 'INTEGER'>]>. Result: <Table\n",
      " creationTime: 1583681238880\n",
      " etag: 'jUSUIOVQaBPYTK3Kejks0A=='\n",
      " id: 'sunny-advantage-266802:cdc_modeled.OVERALL_Health_Status_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583681238925\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'SEQNO'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: '_STATE'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'GENHLTH'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'PHYSHLTH'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'MENTHLTH'\n",
      " type: 'INTEGER'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/sunny-advantage-266802/datasets/cdc_modeled/tables/OVERALL_Health_Status_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'cdc_modeled'\n",
      " projectId: 'sunny-advantage-266802'\n",
      " tableId: 'OVERALL_Health_Status_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n"
     ]
    }
   ],
   "source": [
    "%run OVERALL_Health_Status_beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://beam_cs327e_data_thedataminers/staging/transform-overall-health-status2.1583681736.112524/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://beam_cs327e_data_thedataminers/staging/transform-overall-health-status2.1583681736.112524/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmp66je9eoc', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://beam_cs327e_data_thedataminers/staging/transform-overall-health-status2.1583681736.112524/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://beam_cs327e_data_thedataminers/staging/transform-overall-health-status2.1583681736.112524/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://beam_cs327e_data_thedataminers/staging/transform-overall-health-status2.1583681736.112524/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmp66je9eoc', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://beam_cs327e_data_thedataminers/staging/transform-overall-health-status2.1583681736.112524/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://beam_cs327e_data_thedataminers/staging/transform-overall-health-status2.1583681736.112524/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://beam_cs327e_data_thedataminers/staging/transform-overall-health-status2.1583681736.112524/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 1 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-03-08T15:35:41.669312Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-03-08_08_35_40-14155138580902469935'\n",
      " location: 'us-central1'\n",
      " name: 'transform-overall-health-status2'\n",
      " projectId: 'sunny-advantage-266802'\n",
      " stageStates: []\n",
      " startTime: '2020-03-08T15:35:41.669312Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-03-08_08_35_40-14155138580902469935]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-03-08_08_35_40-14155138580902469935?project=sunny-advantage-266802\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_08_35_40-14155138580902469935 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:40.452Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-03-08_08_35_40-14155138580902469935. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:40.452Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-03-08_08_35_40-14155138580902469935.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:43.534Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:44.313Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-4 in us-central1-a.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:45.122Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:45.151Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 2/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:45.171Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 1/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:45.195Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:45.227Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:45.337Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:45.604Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:45.625Z: JOB_MESSAGE_DETAILED: Fusing consumer Format NULL values into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:45.652Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:45.674Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WriteBundles/WriteBundles into Format NULL values\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:45.695Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Format NULL values\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:45.723Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Pair into Write log 1/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:45.745Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 1/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:45.773Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Reify into Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:45.793Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Write into Write log 1/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:45.823Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 1/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:45.844Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Extract into Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:45.865Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Pair into Write log 2/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:45.889Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 2/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:45.912Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Reify into Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:45.936Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Write into Write log 2/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:45.964Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 2/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:45.990Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Extract into Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:46.013Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/InitializeWrite into Write log 1/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:46.032Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/InitializeWrite into Write log 2/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:46.050Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:46.073Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:46.092Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:46.114Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:46.320Z: JOB_MESSAGE_DEBUG: Executing wait step start29\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:46.369Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:46.396Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:46.408Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:46.422Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:46.430Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-a...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:46.447Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:46.475Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:46.490Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:46.527Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:35:46.555Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_08_35_40-14155138580902469935 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:36:09.546Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running step(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:21.271Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:21.301Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:50.934Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:50.981Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:51.001Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:51.009Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:51.060Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:51.080Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:51.101Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:51.105Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:51.124Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:51.126Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:51.147Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:51.154Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:51.172Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:51.200Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:51.224Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:51.246Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:51.272Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:51.288Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:51.299Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:51.334Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:51.340Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:51.341Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:51.380Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:51.407Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:51.431Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Format NULL values+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:37:52.624Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_6972508230457273519\". You can check its status with the bq tool: \"bq show -j --project_id=sunny-advantage-266802 dataflow_job_6972508230457273519\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:03.268Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_6972508230457273519\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:03.885Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_7314406606525698140\" started. You can check its status with the bq tool: \"bq show -j --project_id=sunny-advantage-266802 dataflow_job_7314406606525698140\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:34.224Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_7314406606525698140\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:34.246Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_7314406606525698140\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:39.289Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_6972508230457270883\". You can check its status with the bq tool: \"bq show -j --project_id=sunny-advantage-266802 dataflow_job_6972508230457270883\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:49.767Z: JOB_MESSAGE_BASIC: BigQuery import job \"dataflow_job_6972508230457270883\" done.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:50.225Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Format NULL values+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:50.277Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:50.305Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:50.322Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:50.342Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:50.379Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:50.403Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:54.676Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:54.723Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:54.771Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:54.798Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:54.821Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:54.843Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:54.873Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:54.897Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:54.939Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:55.750Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:55.802Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:55.857Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:55.882Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:55.902Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:55.924Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:55.948Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:55.973Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:56.026Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:57.478Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:57.523Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:57.574Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:57.615Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:57.669Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:57.719Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:59.600Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:59.646Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:59.698Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:59.751Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:59.793Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:39:59.847Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:40:01.265Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:40:02.161Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:40:02.218Z: JOB_MESSAGE_DEBUG: Executing success step success27\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:40:02.317Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:40:02.366Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:40:02.388Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:41:14.558Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 1 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:41:14.603Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T15:41:14.666Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_08_35_40-14155138580902469935 is in state JOB_STATE_DONE\n"
     ]
    }
   ],
   "source": [
    "%run OVERALL_Health_Status_beam_dataflow.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_results PCollection[Read from BigQuery.None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'cdc_modeled'\n",
      " projectId: 'sunny-advantage-266802'\n",
      " tableId: 'TOBACCO_USE'> referenced by query SELECT SEQNO, _STATE, SMOKE100, SMOKDAY2, LASTSMK2, USENOW3 FROM cdc_modeled.TOBACCO_USE limit 50\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset sunny-advantage-266802:temp_dataset_27f3d5678b6a431fb2bc8ed01adf08f9 does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table sunny-advantage-266802.cdc_modeled.TOBACCO_USE_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'SEQNO'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: '_STATE'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'SMOKE100'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'SMOKDAY2'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'LASTSMK2'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'USENOW3'\n",
      " type: 'INTEGER'>]>. Result: <Table\n",
      " creationTime: 1583685152386\n",
      " etag: '1mLVv7Q8fItHHrh7IJ2KEg=='\n",
      " id: 'sunny-advantage-266802:cdc_modeled.TOBACCO_USE_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583685152421\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'SEQNO'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: '_STATE'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'SMOKE100'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'SMOKDAY2'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'LASTSMK2'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'USENOW3'\n",
      " type: 'INTEGER'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/sunny-advantage-266802/datasets/cdc_modeled/tables/TOBACCO_USE_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'cdc_modeled'\n",
      " projectId: 'sunny-advantage-266802'\n",
      " tableId: 'TOBACCO_USE_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n"
     ]
    }
   ],
   "source": [
    "%run TOBACCO_USE_beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://beam_cs327e_data_thedataminers/staging/transform-tobacco-use.1583683950.422969/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://beam_cs327e_data_thedataminers/staging/transform-tobacco-use.1583683950.422969/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmppb5ok8kl', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://beam_cs327e_data_thedataminers/staging/transform-tobacco-use.1583683950.422969/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://beam_cs327e_data_thedataminers/staging/transform-tobacco-use.1583683950.422969/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://beam_cs327e_data_thedataminers/staging/transform-tobacco-use.1583683950.422969/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmppb5ok8kl', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://beam_cs327e_data_thedataminers/staging/transform-tobacco-use.1583683950.422969/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://beam_cs327e_data_thedataminers/staging/transform-tobacco-use.1583683950.422969/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://beam_cs327e_data_thedataminers/staging/transform-tobacco-use.1583683950.422969/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 1 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-03-08T16:12:35.835021Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-03-08_09_12_34-5759763053903969610'\n",
      " location: 'us-central1'\n",
      " name: 'transform-tobacco-use'\n",
      " projectId: 'sunny-advantage-266802'\n",
      " stageStates: []\n",
      " startTime: '2020-03-08T16:12:35.835021Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-03-08_09_12_34-5759763053903969610]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-03-08_09_12_34-5759763053903969610?project=sunny-advantage-266802\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_09_12_34-5759763053903969610 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:34.713Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-03-08_09_12_34-5759763053903969610. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:34.713Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-03-08_09_12_34-5759763053903969610.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:37.888Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:38.601Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-4 in us-central1-c.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:39.183Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:39.222Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 2/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:39.253Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 1/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:39.296Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:39.337Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:39.449Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:39.708Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:39.748Z: JOB_MESSAGE_DETAILED: Fusing consumer Format NULL values into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:39.780Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:39.822Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WriteBundles/WriteBundles into Format NULL values\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:39.857Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Format NULL values\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:39.895Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Pair into Write log 1/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:39.930Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 1/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:39.969Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Reify into Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:40.013Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Write into Write log 1/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:40.037Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 1/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:40.076Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Extract into Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:40.111Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Pair into Write log 2/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:40.136Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 2/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:40.170Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Reify into Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:40.209Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Write into Write log 2/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:40.243Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 2/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:40.277Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Extract into Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:40.312Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/InitializeWrite into Write log 1/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:40.346Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/InitializeWrite into Write log 2/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:40.422Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:40.453Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:40.492Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:40.528Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:40.735Z: JOB_MESSAGE_DEBUG: Executing wait step start29\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:41.039Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:41.119Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:41.168Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_09_12_34-5759763053903969610 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:41.252Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:41.284Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-c...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:41.349Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:41.436Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:41.460Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:41.526Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:12:41.565Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:13:08.652Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running step(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:14:35.389Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:14:35.438Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:04.938Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:04.993Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:05.017Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:05.056Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:05.094Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:05.133Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:05.172Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:05.207Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:05.232Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:05.238Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:05.270Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:05.277Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:05.301Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:05.303Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:05.334Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:05.338Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:05.341Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:05.374Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:05.409Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:05.413Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:05.451Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:05.483Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:05.514Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:05.542Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:05.592Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Format NULL values+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:15:06.714Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_592784597995934580\". You can check its status with the bq tool: \"bq show -j --project_id=sunny-advantage-266802 dataflow_job_592784597995934580\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:16:12.438Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_592784597995934580\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:16:13.028Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_14319701332988448134\" started. You can check its status with the bq tool: \"bq show -j --project_id=sunny-advantage-266802 dataflow_job_14319701332988448134\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:16:43.374Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_14319701332988448134\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:16:43.419Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_14319701332988448134\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:16:48.872Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_592784597995937400\". You can check its status with the bq tool: \"bq show -j --project_id=sunny-advantage-266802 dataflow_job_592784597995937400\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:16:59.288Z: JOB_MESSAGE_BASIC: BigQuery import job \"dataflow_job_592784597995937400\" done.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:16:59.930Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Format NULL values+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:00.007Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:00.041Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:00.063Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:00.103Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:00.127Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:00.182Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:03.382Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:03.444Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:03.523Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:03.559Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:03.582Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:03.602Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:03.703Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:03.739Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:03.807Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:05.717Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:05.801Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:05.886Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:05.920Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:05.952Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:05.977Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:06.038Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:06.075Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:06.166Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:07.494Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:07.566Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:07.637Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:07.686Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:07.760Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:07.844Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:08.959Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:09.031Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:09.100Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:09.154Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:09.219Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:09.299Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:11.375Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:12.020Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:12.105Z: JOB_MESSAGE_DEBUG: Executing success step success27\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:12.230Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:12.294Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:17:12.327Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:18:45.860Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 1 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:18:45.919Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T16:18:45.950Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_09_12_34-5759763053903969610 is in state JOB_STATE_DONE\n"
     ]
    }
   ],
   "source": [
    "%run TOBACCO_USE_beam_dataflow.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking for primary keys in each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0   50"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(SEQNO) from cdc_modeled.DEMOGRAPHIC_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0   50"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct SEQNO) from cdc_modeled.DEMOGRAPHIC_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  35019"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(SEQNO) from cdc_modeled.DEMOGRAPHIC_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  35019"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct SEQNO) from cdc_modeled.DEMOGRAPHIC_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### As both count SEQNO and count distinct SEQNO gives the same values of DEMOGRAPHIC_Beam_DF of 35019, which confirms that this is primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0   50"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(SEQNO) from cdc_modeled.OVERALL_Health_Status_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0   50"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct SEQNO) from cdc_modeled.OVERALL_Health_Status_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  35019"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(SEQNO) from cdc_modeled.OVERALL_Health_Status_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  35019"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct SEQNO) from cdc_modeled.OVERALL_Health_Status_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### As both count SEQNO and count distinct SEQNO gives the same values of OVERALL_Health_Status_Beam_DF of 35019, which confirms that this is primary key.\n",
    "### This is also the same value as that in DEMOGRAPHIC_Beam_DF, which is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0   50"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(SEQNO) from cdc_modeled.TOBACCO_USE_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0   50"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct SEQNO) from cdc_modeled.TOBACCO_USE_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  35019"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(SEQNO) from cdc_modeled.TOBACCO_USE_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  35019"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct SEQNO) from cdc_modeled.TOBACCO_USE_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### As both count SEQNO and count distinct SEQNO gives the same values of TOBACCO_USE_Beam_DF of 35019, which confirms that this is primary key.\n",
    "### This is also the same value as that in DEMOGRAPHIC_Beam_DF and OVERALL_Health_Status_Beam_DF, which is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0  100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(SEQNO) from cdc_modeled.HEALTH_CARE_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0   50"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct SEQNO) from cdc_modeled.HEALTH_CARE_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Count for HEALTH_CARE_Beam seems to be having issues. This is addressed in Transforms.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  33231"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(SEQNO) from cdc_modeled.HEALTH_CARE_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  24102"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct SEQNO) from cdc_modeled.HEALTH_CARE_Beam_DF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (beam_venv)",
   "language": "python",
   "name": "beam_venv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
